{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXMFkKI-J6Ub"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets accelerate evaluate torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
        "import math\n"
      ],
      "metadata": {
        "id": "kQIbqdodLmiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"yelp_review_full\")\n",
        "dataset\n"
      ],
      "metadata": {
        "id": "sXk3xpTeNHVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Description\n",
        "\n",
        "The Yelp Review Full dataset is obtained from the Hugging Face library.\n",
        "It consists of customer-written reviews in natural language.\n",
        "The dataset is used to fine-tune a Small Language Model on real-world textual data.\n"
      ],
      "metadata": {
        "id": "zekjqdvaN-DY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"distilgpt2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n"
      ],
      "metadata": {
        "id": "oD5y3ClZO-b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Selection\n",
        "\n",
        "DistilGPT-2 is selected as the Small Language Model for this task.\n",
        "It has approximately 82 million parameters, which is well below the 3 billion parameter limit.\n",
        "The model is lightweight and suitable for fine-tuning using Google Colab.\n"
      ],
      "metadata": {
        "id": "ITPuqsH_QhzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n"
      ],
      "metadata": {
        "id": "1WQbf_twQzNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(2000))\n",
        "small_test_dataset = dataset[\"test\"].shuffle(seed=42).select(range(500))\n",
        "\n",
        "tokenized_train = small_train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_test = small_test_dataset.map(tokenize_function, batched=True)\n"
      ],
      "metadata": {
        "id": "d43lfyJkR2tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Subsampling\n",
        "\n",
        "The original dataset is very large, so a smaller subset is selected for training and evaluation.\n",
        "This reduces computational cost while still demonstrating effective fine-tuning of the language model.\n"
      ],
      "metadata": {
        "id": "D1agQYPtR-qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=100,\n",
        "    save_total_limit=2,\n",
        "    fp16=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "bWMF-WyJUtKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Configuration\n",
        "\n",
        "In this step, the training parameters for fine-tuning the model are defined.\n",
        "These parameters control the learning process such as learning rate, batch size, number of epochs, and evaluation method.\n",
        "Proper configuration helps the model train efficiently and produce better results.\n"
      ],
      "metadata": {
        "id": "6ave9WcFU82B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "pF9bpM5uV7sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Fine-tuning\n",
        "\n",
        "The Small Language Model was successfully fine-tuned on the selected dataset.\n",
        "Training was performed for two epochs, and both training and validation loss values decreased, indicating effective learning.\n"
      ],
      "metadata": {
        "id": "Ug5aRhf8Xsep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = trainer.evaluate()\n",
        "eval_results\n"
      ],
      "metadata": {
        "id": "vWynjb4CYsdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation\n",
        "\n",
        "The fine-tuned model was evaluated on the test dataset.\n",
        "Evaluation loss was used as the primary metric to measure the modelâ€™s performance on unseen data.\n"
      ],
      "metadata": {
        "id": "omZq719sYyry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "perplexity = math.exp(eval_results[\"eval_loss\"])\n",
        "perplexity\n",
        "\n"
      ],
      "metadata": {
        "id": "dH1uWQmUY-VD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perplexity\n",
        "\n",
        "Perplexity was calculated from the evaluation loss.\n",
        "A lower perplexity value indicates that the model is better at predicting the next word in a sequence.\n"
      ],
      "metadata": {
        "id": "E2OVtAT1ZEQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"The restaurant was\"\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "outputs = model.generate(\n",
        "    **inputs,\n",
        "    max_length=50,\n",
        "    temperature=0.7,\n",
        "    do_sample=True\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "id": "CsiTV30OZWK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Generation\n",
        "\n",
        "After fine-tuning, the model was used to generate text based on a given prompt.\n",
        "The generated output shows that the model learned meaningful language patterns from the training data.\n"
      ],
      "metadata": {
        "id": "RvfwNH42Zi96"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "In this task, a Small Language Model was successfully fine-tuned on a text dataset from Hugging Face.\n",
        "The model showed improved performance after training, as reflected by evaluation loss, perplexity, and generated text.\n",
        "This experiment demonstrates the complete workflow of fine-tuning and evaluating a language model.\n"
      ],
      "metadata": {
        "id": "QQkF2i7DZudX"
      }
    }
  ]
}